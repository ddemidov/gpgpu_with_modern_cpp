\documentclass[1p]{elsarticle}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage[colorlinks,unicode,linkcolor=black]{hyperref}
\usepackage{listings}
\lstset{
    language=C++,
    basicstyle=\small,
    columns=flexible,
    showstringspaces=false,
    frame=single
    }
\newcommand{\code}[1]{\lstinline|#1|}
\newcommand{\figref}[1]{Fig.~\ref{#1}}

\journal{Journal of Parallel and Distributed Computing}

\begin{document}

\begin{frontmatter}

\title{Programming OpenCL and CUDA:\\a Case Study Using Modern C++ Libraries}

\author{Karsten Ahnert}
\ead{kahnert@uni-potsdam.de}
\address{
Institut f\"ur Physik und Astronomie, Universit\"at Potsdam,\\
Karl-Liebknecht-Strasse 24/25, 14476 Potsdam-Golm, Germany
}

\author{Denis Demidov}
\ead{ddemidov@ksu.ru}
\address{
Kazan Branch of Joint Supercomputer Center,
Russian Academy of Sciences,\\
Lobachevsky st. 2/31, 420008 Kazan, Russia
}

\author{Karl Rupp}
\ead{rupp@iue.tuwien.ac.at}
\address{
Institute for Microelectronics, TU Wien,\\
Gusshausstrasse 27-29/E360, A-1040 Wien, Austria
}

\begin{abstract}
    We present comparison of several modern C++ libraries intended for OpenCL
    and CUDA programming. The comparison is based on odeint~--- framework for
    solution of ordinary differential equations. Odeint is designed in a very
    flexible way such that the algorithms are completely independent from the
    underlying containers and even from the basic algebraic computations. This
    allows to effectively use such libraries as VexCL, ViennaCL or Thrust to
    solve ODEs with either OpenCL or CUDA technologies. We found that OpenCL
    and CUDA work equally well for problems of large sizes, although OpenCL is
    not well suited for smaller problems due to its higher initialization
    overhead.
\end{abstract}

\begin{keyword}
    GPGPU \sep OpenCL \sep CUDA \sep Modern C++ libraries
\end{keyword}

\end{frontmatter}

\section{Introduction}

Recently, GPGPU based computing has acquired considerable momentum in
scientific community. This is confirmed both by increasing numbers of
GPGPU-related publications and GPU based supercomputers in
top500\footnote{\href{http://top500.org/}{http://top500.org/}} list. Major
programming frameworks are NVIDIA CUDA and OpenCL.  The former is proprietary
parallel computing architecture developed by Nvidia for general purpose
computing on Nvidia graphics cards, and the latter is open, royalty-free
standard for cross-platform, parallel programming of modern processors backed
by Khronos group. The frameworks have their distinctive pros and cons. CUDA has
more mature programming environment with larger set of scientific libraries;
but it is only supported on NVIDIA hardware. OpenCL is an open standard
supported on wide range of hardware but it requires much larger amount of
boilerplate code from a developer.

Both technologies are able to provide scientists with vast computational
resources of modern GPU cards. But the power comes with a price: GPGPU
programming has a steep learining curve. Programmer needs to familiarize
himself with (slightly) new programming language and, more importantly, with
new programming paradigm. However, the entry price may be lowered with help of
specialized libraries. CUDA provides several such libraries (BLAS
implementation, Fast Fourier Transform, Thrust and others). But there are many
third party librares for both CUDA and OpenCL.

This paper presents comparison of several modern C++ libraries aimed at ease of
GPGPU development. We look at both ease of use and performance of the libraries
under consideration in the context of solving ordinary differential equations.
The comparison is based on odeint~--- modern C++ library for solution of ODEs.
Odeint is designed in a very flexible way such that the algorithms are
completely independent from the underlying containers and even from the basic
algebraic computations. This allows to effectively use libraries implementing
basic linear algebra operations with either OpenCL or CUDA technologies for
solution of ODEs.



\begin{description}
    \item[Odeint] is a modern C++
	library\footnote{\href{http://odeint.com}{http://odeint.com}} for
	numerically solving Ordinary Differential Equations. It is developed in
	a generic way using Template Metaprogramming which leads to
	extraordinary high flexibility at top performance. The numerical
	algorithms are implemented independently of the underlying arithmetics.
	This results in an incredible applicability of the library, especially
	in non-standard environments. For example, odeint supports matrix
	types, arbitrary precision arithmetics and can be easily adopted to use
	either CUDA or OpenCL frameworks.  Odeint is used in this work as a
	framework for comparison of other libraries.
    \item[Thrust] is a parallel algorithms
	library\footnote{\href{http://thrust.github.com}{http://thrust.github.com}}
	which resembles the C++ Standard Template Library. Thrust's high-level
	interface greatly enhances developer productivity while enabling
	performance portability between GPUs and multicore CPUs. Thrust is
	distributed with NVIDIA CUDA Toolkit since version 4.1.
    \item[VexCL] is vector expression template
	library\footnote{\href{https://github.com/ddemidov/vexcl}{https://github.com/ddemidov/vexcl}}
	for OpenCL. It has been created for ease of OpenCL developement with
	C++.  VexCL strives to reduce amount of boilerplate code needed to
	develop OpenCL applications. The library provides convenient and
	intuitive notation for vector arithmetic, reduction, and sparse
	matrix-vector multiplication.  Multi-device and even multi-platform
	computations are supported. 
    \item[ViennaCL] (The Vienna Computing Library) is a scientific computing
	library\footnote{\href{http://viennacl.sourceforge.net}{http://viennacl.sourceforge.net}}
	written in C++ and based on OpenCL. It allows simple, high-level access
	to the vast computing resources available on parallel architectures
	such as GPUs and is primarily focused on common linear algebra
	operations (BLAS levels 1, 2 and 3) and the solution of large systems
	of equations by means of iterative methods with optional
	preconditioner.
\end{description}

%Odeint supports Thrust and VexCL natively, but for ViennaCL we needed to
%provide adaptation code. Since ViennaCL already supports expression templates
%it can directly be used with the \code{vector_space_algebra} of odeint. There
%is no need to introduce an additional algebra or new operations. So in order to
%use \code{viennacl::vector} with odeint we only only needed to adapt the
%resizing operation. Resizing in odeint is necessary since many solvers need
%temporary state types. These state types need to be constructed and initialized
%which is done by the resizing mechanism of odeint.
%
%The resizing mechanism of odeint consist of three class templates. These
%classes are \code{is_resizeable<>} which is simply a meta function telling
%odeint if the type is really resizable. The second class is
%\code{same_size_impl<>} which has a static method \code{same_size} taking two
%\code{state_type} instances as arguments and returning if both instances have
%the same size. The third class is \code{resize_impl<>} which performs the
%actual resizing. These classes have a default implementation and can be
%specialized for any type.  For ViennaCL the specialization is very simple and
%is presented on \figref{fig:adapt:viennacl}.
%
%We were only able to test damped harmonic oscillator example with ViennaCL,
%since the library lacks such vector operations as elementwise multiplication or
%function application necessary for the other examples.  Nevertheless we
%consider comparison with ViennaCL interesting enough to include in this paper.
%Indeed, ViennaCL and VexCL employ somewhat different approaches to OpenCL
%kernel generation. ViennaCL has limited number of kernels, which coincide
%functionally with BLAS level 1 routines. These kernels are compiled in batch at
%the program start to allow for faster initialization. However, due to this
%design decision each vector expression may result in launch of more than one
%kernel.  On the other hand, VexCL generates and compiles single kernel for each
%vector expression it encounters.  This leads to higher initialization overhead,
%but should prove more effective in the long runs. It should be noted that main
%aim of ViennaCL is provision of iterative solvers for large sparse systems of
%equations. In this context complex vector expressions are rare and we think
%that authors of ViennaCL made correct design decision.  However, we think it is
%interesting to compare approaches of VexCL and ViennaCL.

\section{Adapting odeint}

\begin{figure}
\begin{lstlisting}
typedef std::array<double, 3> state_type;
state_type x1, x2;
// Initialize x1 and x2.

double dt = 0.1;
odeint::range_algebra algebra;
// The following line computes x1 = dt * x2 for all elements of x1 and x2:
algebra.for_each2(x1, x2, default_operations::scale_sum1(dt));
\end{lstlisting}
\caption{An example of range algebra in odeint.}
\label{fig:odeintops}
\end{figure}

Odeint provides a mechanism which lets the user change the way how the
elementary numerical computations are performed. This mechanism consists of a
combination of state type, algebra and operations. State type represents the
state of the ODE being solved and is usually a vector type like
\code{std::vector<>} or \code{std::array<>}. The algebra is responsible for
iterating through all elemnts of the state whereas the operations are
responsible for the elementary operations. \figref{fig:odeintops} provides an
example of using range algebra. Here \code{for_each2} is used, which means that
two state types are iterated. The operation is a \code{scale_sum1} which simply
calculates \code{x1[i] = dt * x2[i]}. Odeint provides a set of predefined
algebras, which includes:
\begin{itemize}
    \item \code{range_algebra}: default algebra which works on Boost.Ranges
    \item \code{array_algebra}: specialized algebra for boost::array
    \item \code{fusion_algebra}: algebra for compile-time sequences like
	\code{boost::fusion::vector}, \code{std::tuple}, etc.
    \item \code{vector_space_algebra}: algebra for vector space types which
	provide overloaded arithmetic operators for elementwise operations.
\end{itemize}

Many libraries for vector and matrix types provide expression templates for the
elementary operations. Such libraries do not need an own algebra but can be
used with the \code{vector_space_algebra} and the \code{default_operations}
which simply calls the operations directly on the matrix or vector type. In
this case only odeint resizing mechanism has to be adapted.

In the following subsections we describe odeint adaptation for GPGPU libraries
under consideration. We should mention that odeint now supports all of the
mentioned libraries natively. However, providing adaptation examples serves our
goal of comparing ease of use of the libraries.

\subsection{Thrust}
\subsection{VexCL}
\subsection{ViennaCL}

\section{Numerical experiments}

\subsection{Lorenz Attractor Ensemble}

In the first example we will use the Lorenz system and study its dependence on
one of the parameters. The Lorenz system is a system of three coupled ODEs
which shows chaotic behavior for a large range of parameters. The ODE reads
\begin{align}
    \frac{dx}{dt} &= -\sigma \left( x - y \right), \\
    \frac{dy}{dt} &= R x - y - xz, \\
    \frac{dz}{dt} &= -bz + xy.
\end{align}

We will study the dependence on the parameter $R$. Therefore, we create a large
set of these systems (each with a different parameter $R$), pack them all into
one system and solve them simultaneously on the GPU.

\subsection{Chain of Coupled Phase Oscillators}

As a second example we choose a chain of coupled phase oscillators. Phase
oscillators are a very simplified version of usual oscillator where the state
is described by a $2\pi$ periodic variable. If a single phase oscillator is
uncoupled its phase $\phi$ is described by a linear growth $d\phi/dt = \omega$
where $\omega$ is the phase velocity. Therefore, interesting behavior can only
be observed if two or more oscillators are coupled. In fact, a system of
coupled phase oscillators is a prominent example of an emergent system where
the coupled system shows a more complex behavior than its constitutes.

The concrete example we analyze here is:
\begin{equation}
    \frac{d\phi_i}{dt} = \omega_i + \sin( \phi_{i+1} - \phi_i) + \sin( \phi_i
    - \phi_{i-1}).
\end{equation}
Note that $\phi_i$ is a function of the time, the index $i$ denotes here the
$i$-th phase in the chain.

\subsection{Damped Harmonic Oscillator Ensemble}

\subsection{Disordered Ham Lattice}

\section{Results}

\begin{figure}
    \begin{center}
	\includegraphics[width=\textwidth]{data/lorenz_ensemble/perfcmp}
    \end{center}
    \caption{Lorenz attractor ensemble results}
    \label{fig:lorenz:perf}
\end{figure}

\begin{figure}
    \begin{center}
	\includegraphics[width=\textwidth]{data/phase_oscillator_chain/perfcmp}
    \end{center}
    \caption{Phase oscillator chain results}
    \label{fig:phase:perf}
\end{figure}

\begin{figure}
    \begin{center}
	\includegraphics[width=\textwidth]{data/damped_oscillator/perfcmp}
    \end{center}
    \caption{Damped oscillator ensemble results}
    \label{fig:damped:perf}
\end{figure}

\begin{figure}
    \begin{center}
	\includegraphics[width=\textwidth]{data/disordered_ham_lattice/perfcmp}
    \end{center}
    \caption{Disordered Ham lattice results}
    \label{fig:lattice:perf}
\end{figure}

\begin{figure}
    \begin{center}
	\subfigure[
	Damped oscillator ensemble
	]{\includegraphics[width=0.4\textwidth]{data/damped_oscillator/scaling}}\quad
	\subfigure[
	Disordered Ham lattice
	]{\includegraphics[width=0.4\textwidth]{data/disordered_ham_lattice/scaling}}\\
	\subfigure[
	Lorenz attractor ensemble
	]{\includegraphics[width=0.4\textwidth]{data/lorenz_ensemble/scaling}}\quad
	\subfigure[
	Damped phase oscillator chain
	]{\includegraphics[width=0.4\textwidth]{data/phase_oscillator_chain/scaling}}
    \end{center}
    \caption{VexCL scaling with multigpu computation}
    \label{fig:scaling}
\end{figure}

\section{Further optimizations}

It may be said that performance we got so far is not optimal. Indeed, generic
odeint algorithms uses temporary vector variables. For example, fourth-order
Runge-Kutta method used in our examples uses at least four temporary state
variables on each integration step. All of those temporaries are full-blown
vectors that waste global memory reads and writes. 

\begin{figure}
\begin{lstlisting}
double2 system_function(
    double omega, double amp, double offset, double omega_d,
    double dt, double t, double2 s
    )
{
    double eps = offset + amp * cos(omega_d * t);
    double2 dsdt;
    dsdt.x = dt * (eps * s.x + omega * s.y);
    dsdt.y = dt * (eps * s.y - omega * s.x);
    return dsdt;
}
kernel void dumped_oscillator(
    ulong  n, global double *X, global double *Y,
    double omega, double amp, double offset, double omega_d,
    double dt, double t
    )
{
    double2 s, dsdt, k1, k2, k3, k4;
    for(size_t gid       = get_global_id(0),
               grid_size = get_global_size(0);
        gid < n; gid += grid_size)
    {
        s.x = X[gid];
        s.y = Y[gid];
        k1 = system_function(omega, amp, offset, omega_d, dt, t, s);
        k2 = system_function(omega, amp, offset, omega_d, dt,
                t + 0.5 * dt, s + 0.5 * k1);
        k3 = system_function(omega, amp, offset, omega_d, dt,
                t + 0.5 * dt, s + 0.5 * k2);
        k4 = system_function(omega, amp, offset, omega_d, dt,
                t + dt, s + k3);
        s += (k1 + 2 * k2 + 2 * k3 + k4) / 6;
        X[gid] = s.x;
        Y[gid] = s.y;
    }
};

\end{lstlisting}
\caption{Hand-coded kernel implementing single iteration of 4th order
Runge-Kutta method.}
\label{fig:code:customkrn}
\end{figure}

It is of course possible to manually create computational kernel corresponding
to the full integration step. \figref{fig:code:customkrn} shows just this
kernel. Unfortunately, by choosing this path we lost generality that odeint
provides.

\begin{figure}
\begin{lstlisting}
struct oscillator {
    value_type omega, amp, offset, omega_d;
    sym_value &sym_time;

    oscillator(value_type omega, value_type amp, value_type offset,
               value_type omega_d, sym_value &sym_time)
        : omega(omega), amp(amp) , offset(offset) , omega_d(omega_d),
          sym_time(sym_time)
    {}

    void operator()( const sym_state &x , sym_state &dxdt , value_type t ) {
        sym_value eps;
        eps = m_offset + m_amp * cos( m_omega_d * (sym_time + t) );
        dxdt[0] = eps * x[0] + m_omega * x[1];
        dxdt[1] = eps * x[1] - m_omega * x[0];
    }
};
\end{lstlisting}
\caption{System function used in automatic kernel generation.}
\label{fig:code:symsysfunc}
\end{figure}

\begin{figure}
\begin{lstlisting}
typedef double value_type;
typedef vex::generator::symbolic<value_type> sym_value;
typedef std::array<sym_value,2> sym_state;

// Custom kernel body will be recorded here:
std::ostringstream body;
vex::generator::set_recorder(body);

// State types that would become kernel parameters:
sym_state sym_S = {sym_value::VectorParameter, sym_value::VectorParameter};
sym_value sym_time(sym_value::ScalarParameter);

// Symbolic stepper:
odeint::runge_kutta4<
        sym_state, value_type, sym_state, value_type,
        odeint::range_algebra, odeint::default_operations
        > sym_stepper;

oscillator sys(1.0, 0.2, 0.0, 1.2, sym_time);
sym_stepper.do_step(std::ref(sys), sym_S, 0, dt);

// Now that expression sequence is recorded, we build OpenCL kernel:
auto kernel = vex::generator::build_kernel(ctx.queue(),
        "damped_oscillator", body.str(), sym_S[0], sym_S[1], sym_time
        );

// Actual data (initialization skipped).
vex::vector<value_type> X(ctx.queue(), n);
vex::vector<value_type> Y(ctx.queue(), n);

// Integration loop:
for(value_type t = 0; t < t_max; t += dt) kernel(X, Y, t);
\end{lstlisting}
\caption{Automatic generation of OpenCL kernel corresponding to 4th order
Runge-Kutta method}
\label{fig:code:krnbuilder}
\end{figure}

VexCL library provides kernel generation mechanism that is able to solve this
problem. It allows transparent conversion of generic CPU algorithms to OpenCL
kernels. In order to do this conversion one needs to record sequence of
arithmetic expressions made by an algorithm.  The recording is done with help
of \code{vex::generator::symbolic<T>} class. The class supports arithmetic
expression templates and simply outputs to provided stream any expressions it
is being subjected to. This technique is demonstrated on
\figref{fig:code:symsysfunc} and~\ref{fig:code:krnbuilder}. Its advantage is
that we are able to select any stepper from odeint library (or any other
algorithm) for the generated kernel. \figref{fig:genkernel} presents
performance comparison of Thrust-based odeint solution with hand-coded and
generated OpenCL kernels. Both hand-coded and generated kernels show very
similar performance and outperform Thrust-based odeint solution by a factor of
5 for large problem sizes. Moreover, generated kernel outperforms hand-coded
kernel by a small margin. We beleive this is due to the fact that VexCL kernel
generator unrolls all operations in the kernel and hard-codes any constants it
encounters in expression sequence.

\begin{figure}
    \begin{center}
	\includegraphics[width=\textwidth]{data/damped_oscillator/genkernel}
    \end{center}
    \caption{Performance of damped oscillator example with hand-coded and
    generated OpenCL kernels compared with Thrust-based odeint solution.}
    \label{fig:genkernel}
\end{figure}

\section{Conclusion}

Performance-wise, there is almost no difference between various platforms and
libraries when those are run on the same hardware. As we have shown, various
computational problems may be solved effectively in terms of both human and
machine time with help of modern high level libraries.  There are some
differences in the programming interfaces of the libraries which may be crucial
for ones specific application. 

Thrust is more low level and its interface is very close to C++ STL library.
OpenCL libraries that we looked at provide more convenient interface for a
scientific programmer. VexCL has richer set of elementwise vector operations,
but ViennaCL has extensive set of sparse linear systems solvers (very important
feature which we did not discuss in this paper).

Regarding CUDA vs OpenCL comparison, we believe that OpenCL has two major
advantages w.r.t. CUDA: first, it has much wider range of supported hardware
which is only going to widen with time, since OpenCL is open standard supported
by major hardware producers. Second advantage of OpenCL is at the same time its
drawback: one has to (or may to) compile his kernels at compile time. This adds
overhead notable for smaller workloads but at the same time it allows one to
transparently build much more effective kernels, as it has been shown in this
paper. 

\section{Acknowledgments}

This work has been partially supported by RFBR grant No 12-07-0007. We also
would like to thank Gradient
JSC\footnote{\href{http://www.gradient-geo.com/en}{http://www.gradient-geo.com/en}}
for kindly provided hardware.

\nocite{*}
\bibliographystyle{model1-num-names}
\bibliography{ref}

\end{document}
